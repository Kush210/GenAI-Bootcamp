{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/home/kush_210/Vettura-genai/vettura/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-06 19:02:46.138556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738886566.276563  143951 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738886566.340845  143951 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-06 19:02:46.775703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import streamlit as st\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pytube import YouTube\n",
    "# from langchain.document_loaders import WebBaseLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from transformers import pipeline\n",
    "# from pydub import AudioSegment\n",
    "import yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143951/583273140.py:14: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm_llama3 = Ollama(model=\"llama3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=QEzbZKtLi-g\n",
      "[youtube] QEzbZKtLi-g: Downloading webpage\n",
      "[youtube] QEzbZKtLi-g: Downloading tv client config\n",
      "[youtube] QEzbZKtLi-g: Downloading player 9c6dfc4a\n",
      "[youtube] QEzbZKtLi-g: Downloading tv player API JSON\n",
      "[youtube] QEzbZKtLi-g: Downloading ios player API JSON\n",
      "[youtube] QEzbZKtLi-g: Downloading m3u8 information\n",
      "[info] QEzbZKtLi-g: Downloading 1 format(s): 251-5\n",
      "[download] Destination: ./audio\n",
      "[download] 100% of    3.56MiB in 00:00:00 at 3.99MiB/s   \n",
      "[ExtractAudio] Destination: ./audio.wav\n",
      "Deleting original file ./audio (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "# Set options for yt-dlp\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',  # Select the best audio quality\n",
    "    'outtmpl': './audio',  # Output file name with .wav extension\n",
    "    'postprocessors': [{  # Extract audio using ffmpeg and save as WAV\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192',  # Bitrate doesn't apply to WAV but is kept for consistency\n",
    "    }],\n",
    "    'ffmpeg_location': '/usr/bin/ffmpeg',\n",
    "}\n",
    "\n",
    "# Ollama model for Llama3\n",
    "llm_llama3 = Ollama(model=\"llama3\")\n",
    "# output_parser = StrOutputParser()\n",
    "\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=QEzbZKtLi-g\"\n",
    "\n",
    "# Create a YouTube object with the URL\n",
    "yt = YouTube(YOUTUBE_VIDEO)\n",
    "\n",
    "# Get the publication date\n",
    "Date = yt.publish_date\n",
    "\n",
    "# Get the highest quality audio stream\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "  ydl.download([YOUTUBE_VIDEO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kush_210/Vettura-genai/vettura/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Today, we're diving into the core concepts of Docker, the technology that we shape how we build, deploy, and scale applications. It's simple, consistent, and it works everywhere. Let's start with the\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Whisper model\n",
    "# whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)\n",
    "transcript = whisper(\"audio.wav\",return_timestamps=True)['text']\n",
    "print(transcript[:200])\n",
    "\n",
    "# Save transcript to transcription.txt\n",
    "with open(\"transcription.txt\", \"w\") as file:\n",
    "    file.write(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the blog article created from the provided transcription:\n",
      "\n",
      "**Title:** Mastering Docker: Core Concepts for Building, Deploying, and Scaling Applications\n",
      "### Foundation of Docker: The Dockerfile\n",
      "\n",
      "Docker is a technology that has revolutionized how we build, deploy, and scale applications. In this article, we'll dive into the core concepts of Docker, starting with the foundation - the Dockerfile.\n",
      "\n",
      "The Dockerfile is where we define the environment our application needs. We specify our base image, carefully selecting what we need and nothing more. By choosing slim variants of official images, combining commands to reduce layers, and removing build tools after compilation, we can keep our images lean and efficient. Each instruction in our Dockerfile creates a new layer, which captures specific changes to files and their configuration.\n",
      "\n",
      "### Docker Images: Self-Contained Packages\n",
      "\n",
      "The layers created by our Dockerfile come together to form Docker images. These are self-contained packages that include everything our application needs - the runtime, system tools, libraries, and application code all bundled together. The best part? Images are immutable, meaning once built, they cannot be modified, only replaced with new versions.\n",
      "\n",
      "This immutability guarantees that what we test in development runs identically in production. No more worrying about different environments or configurations!\n",
      "\n",
      "### Containers: Lightweight Runtime Instances\n",
      "\n",
      "Now let's talk about containers. These runtime instances of our images are lightweight because they share the whole system's kernel. Yet each container maintains straight isolation through Linux kernel features, such as namespaces and cgroups.\n",
      "\n",
      "This architecture allows multiple containers to run from the same image, each with its own isolated state. Whether you're running a single container or a fleet of them, Docker provides the foundation for scalable and reliable applications.\n",
      "\n",
      "### Distribution: Docker Registries\n",
      "\n",
      "When it comes to distribution, we rely on Docker registries. These repositories become the single source of truth for our images. Whether we're using Docker Hub publicly or running our private registry internally, the principle remains the same - build once, run anywhere.\n",
      "\n",
      "This solves the classic \"it works on my machine\" problem!\n",
      "\n",
      "### Data Persistence: Volumes\n",
      "\n",
      "Data persistence in containers introduces an interesting challenge. Docker volumes provide the solution. Unlike a container's writable layer, volumes exist independently and persist data across container life cycles. We can share them between containers and mount them to specific paths, which is good for databases, shared assets, configuration files, and any data we need to preserve.\n",
      "\n",
      "### Orchestrating Containers: Compose and Kubernetes\n",
      "\n",
      "As our applications grow more complex, we turn to Docker Compose. This tool lets us define multi-container applications in a simple YAML file. With Compose, we describe our entire setup - services, networks, volumes, and keep it all under version control.\n",
      "\n",
      "In production, we often move to container orchestrators like Kubernetes. These platforms handle the complexity of running containers at scale, including automatic failover, load balancing, rolling updates, and self-healing infrastructure.\n",
      "\n",
      "### Interacting with Docker: The CLI\n",
      "\n",
      "At the heart of our interaction with Docker is the CLI (Command Line Interface). This is where we interact with Docker, building images, running containers, managing networks. The Docker daemon does the hard work in the background, making it all feel effortless.\n",
      "\n",
      "The container runtime landscape extends beyond Docker. Tools like Containerd and Podman offer specialized runtime focused purely on container execution and image management. They are particularly useful when working with orchestrators like Kubernetes.\n",
      "\n",
      "If you enjoyed this video, you might enjoy our System Design newsletter as well! It covers topics and trends in large-scale system design, trusted by 1 million readers. Subscribe at [blog.bybico.com](http://blog.bybico.com).\n"
     ]
    }
   ],
   "source": [
    "with open(\"transcription.txt\") as file:\n",
    "      transcription = file.read()\n",
    "\n",
    "#create a spinned article from this video transcription. Create a title, subtitle and a relevant image for the spinned article. \n",
    "system_prompt = \"\"\"You are an assitant which creates a blog article from provided transcription of a video. The blog should contain appropriate title and subtitle. \n",
    "                  Use markdown fromat for formatting the article.\\n\\n\n",
    "                  \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{video_transcription}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm_llama3 | StrOutputParser()\n",
    "# Now, we need to invoke this chain with a transcription\n",
    "video_transcription = transcription  # Assuming transcription is already loaded from the file\n",
    "\n",
    "# Invoke the chain to process the input\n",
    "response = chain.invoke({\"video_transcription\": video_transcription})\n",
    "\n",
    "# Output the result (the spinned article with title, subtitle, and image prompt)\n",
    "print(response)\n",
    "#Generate the audio for the text of the spinned article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_system_prompt = \"\"\"You are an assitant which creates a image prompt  from provided blog article.Only give the image prompt\\n\\n \"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", img_system_prompt),\n",
    "        (\"user\", \"{article}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm_llama3 | StrOutputParser()\n",
    "\n",
    "# Invoke the chain to process the input\n",
    "img_prompt = chain.invoke({\"article\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the image prompt:\n",
      "\n",
      "\"Image of a containerized application architecture: Dockerfile, Images, Containers, Registries, Volumes, Compose, Kubernetes, and CLI, representing building, deploying, and scaling applications.\"\n"
     ]
    }
   ],
   "source": [
    "print(img_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-zWe7tdzyNIozBnwMRHtVvoQr/user-3BxQN6mtOJWeimCKPjCyXm8y/img-7f5NeRTKVXK8cK1o3BxZNQ93.png?st=2025-02-06T23%3A11%3A03Z&se=2025-02-07T01%3A11%3A03Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-02-06T14%3A08%3A40Z&ske=2025-02-07T14%3A08%3A40Z&sks=b&skv=2024-08-04&sig=lBhWiKvwvWCYPBqJHtdQ7wjDpo2wBMKMrUazjq%2Bbgxg%3D\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "img = client.images.generate(\n",
    "                model=\"dall-e-3\", prompt=img_prompt, size=\"1024x1024\", n=1\n",
    "            )\n",
    "img_url = img.data[0].url\n",
    "print(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "image = requests.get(img_url)\n",
    "image = Image.open(BytesIO(image.content))\n",
    "image.save(\"image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcription.txt\") as file:\n",
    "      transcription = file.read()\n",
    "\n",
    "client = OpenAI()\n",
    "speech_file_path = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=transcription,\n",
    ")\n",
    "with open(speech_file_path, \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vettura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
