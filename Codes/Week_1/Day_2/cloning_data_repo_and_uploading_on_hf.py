# -*- coding: utf-8 -*-
"""Cloning_data_repo_and_uploading_on_HF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W969zixFP0Gx5FC7ckdta6IgBxd2El3o
"""

!pip install datasets

from datasets import load_dataset

# Load the Amazon Reviews 2023 dataset
dataset = load_dataset("McAuley-Lab/Amazon-Reviews-2023","raw_meta_Appliances")

# View the dataset structure
print(dataset)

import pandas as pd

# Access the 'full' split
full_data = dataset['full']

# View the first few records
data = full_data[:5]
pd.DataFrame(data)

# Take a random 2% sample
subset = full_data.train_test_split(test_size=0.2)['test']

# Verify the size of the subset
print(f"Original size: {len(full_data)}, Subset size: {len(subset)}")
subset.save_to_disk("amazon_reviews_subset")

# Login to Hugging Face
from huggingface_hub import notebook_login
notebook_login()

from huggingface_hub import HfApi
from datasets import Dataset

# Create a new dataset repository
repo_id = "your_username/amazon-appliances-data-subset"  # Replace `your_username` with your Hugging Face username
api = HfApi()
api.create_repo(repo_id=repo_id, repo_type="dataset")

# Push the dataset to Hugging Face
subset.push_to_hub(repo_id=repo_id, token=True)

print(f"Dataset uploaded to: https://huggingface.co/datasets/{repo_id}")

