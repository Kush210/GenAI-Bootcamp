{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BGE model is created by the Beijing Academy of Artificial Intelligence (BAAI).\n",
        "BGE (BAAI General Embedding) focuses on retrieval-augmented LLMs. Its\n",
        "FlagEmbedding can map any text to a low-dimensional dense vector which can be used for tasks like retrieval, classification, clustering, or semantic search. And it also can be used in vector databases for LLMs.\n",
        "\n",
        "Refrences:\n",
        "1. https://github.com/FlagOpen/FlagEmbedding\n",
        "2. https://huggingface.co/BAAI/bge-large-en\n",
        "\n",
        "`pip install -U FlagEmbedding`"
      ],
      "metadata": {
        "id": "opwZgQ3OiBeX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bft4XqNqgCGl"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U FlagEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from FlagEmbedding import FlagModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cdist"
      ],
      "metadata": {
        "id": "kI0o44a9kMj3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FlagModel(\"BAAI/bge-large-en\",\n",
        "                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages\",\n",
        "                  use_fp16=False)"
      ],
      "metadata": {
        "id": "eesMNlSSkMbw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_1 = \"Gujarat, located on the western coast of India, is rich in ancient history. Its settlements date back to the Indus Valley Civilization, with cities like Dholavira showing advanced urban planning. Over 4,000 years ago, it became a center of maritime trade. Gujarat played a crucial role in the spread of culture across the Arabian Sea, with links to Mesopotamia, the Persian Gulf, and even Africa.\"\n",
        "sentences_2 = \"The history of human settlement in Rajasthan goes back more than 100,000 years, with the Indus Valley Civilization marking one of the earliest urban settlements. Sites like Kalibangan show evidence of fire altars, and Rajasthan's strategic location made it a hub for trade. The region's culture and history have been shaped by its rich archaeological past, which continues to be explored.\"\n",
        "sentences_3 = \"Uttar Pradesh, a state in northern India, has a diverse economy dominated by agriculture, services, and manufacturing. The state is a significant contributor to India’s agriculture sector, producing crops like wheat, rice, and sugarcane. In recent years, the economy has shifted toward industrial growth, including sectors like textiles, electronics, and infrastructure development. The state is also a key player in India’s political landscape.\""
      ],
      "metadata": {
        "id": "2BKi3ae9kcDf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for the three paragraphs\n",
        "embeddings_1 = model.encode(sentences_1)\n",
        "embeddings_2 = model.encode(sentences_2)\n",
        "embeddings_3 = model.encode(sentences_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfajv07bk7WB",
        "outputId": "f17bbfe4-6f22-43b4-a7af-8d9e090e94ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity between sentences\n",
        "# The cosine_similarity function expects its inputs to be in a specific format: 2D arrays with shape (n_samples, n_features) we need to reshape it\n",
        "cosine_sim_1_2 = cosine_similarity(embeddings_1.reshape(1, -1), embeddings_2.reshape(1, -1))\n",
        "cosine_sim_1_3 = cosine_similarity(embeddings_1.reshape(1, -1), embeddings_3.reshape(1, -1))\n",
        "cosine_sim_2_3 = cosine_similarity(embeddings_2.reshape(1, -1), embeddings_3.reshape(1, -1))"
      ],
      "metadata": {
        "id": "nRsKZcEek_pR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cosine Similarity between Paragraph 1 and 2:\", cosine_sim_1_2)\n",
        "print(\"Cosine Similarity between Paragraph 1 and 3:\", cosine_sim_1_3)\n",
        "print(\"Cosine Similarity between Paragraph 2 and 3:\", cosine_sim_2_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peb8xbBeGKo",
        "outputId": "0bca19c3-3e99-436c-f03e-9d22c4e30914"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity between Paragraph 1 and 2: [[0.8800514]]\n",
            "Cosine Similarity between Paragraph 1 and 3: [[0.7762312]]\n",
            "Cosine Similarity between Paragraph 2 and 3: [[0.7639016]]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Compute Euclidean distance between sentences\n",
        "#  the cdist function from scipy.spatial.distance expects 2D arrays with shape (n_samples, n_features) as inputs.\n",
        "euclidean_dist_1_2 = cdist(embeddings_1.reshape(1, -1), embeddings_2.reshape(1, -1), metric='euclidean')\n",
        "euclidean_dist_1_3 = cdist(embeddings_1.reshape(1, -1), embeddings_3.reshape(1, -1), metric='euclidean')\n",
        "euclidean_dist_2_3 = cdist(embeddings_2.reshape(1, -1), embeddings_3.reshape(1, -1), metric='euclidean')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xDcwcpv6nlN-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Euclidean Distance between Paragraph 1 and 2:\", euclidean_dist_1_2)\n",
        "print(\"Euclidean Distance between Paragraph 1 and 3:\", euclidean_dist_1_3)\n",
        "print(\"Euclidean Distance between Paragraph 2 and 3:\", euclidean_dist_2_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFypuBv6lEV6",
        "outputId": "aefea421-c740-4635-c9d4-182cd42c19d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Distance between Paragraph 1 and 2: [[0.48979285]]\n",
            "Euclidean Distance between Paragraph 1 and 3: [[0.66898238]]\n",
            "Euclidean Distance between Paragraph 2 and 3: [[0.68716573]]\n"
          ]
        }
      ]
    }
  ]
}