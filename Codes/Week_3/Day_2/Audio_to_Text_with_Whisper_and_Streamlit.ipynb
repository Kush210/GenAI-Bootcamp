<<<<<<< HEAD
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Designed to run on Colab with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o80fU1RwFXC5"
      },
      "outputs": [],
      "source": [
        "! pip install streamlit transformers torch streamlit-audiorecorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7HQV9ooK-6",
        "outputId": "eefd9731-e3db-4a7a-dea9-8af28f5b8d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting audioRecordAndPlay.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile audioRecordAndTranscribe.py\n",
        "\n",
        "import streamlit as st\n",
        "from audiorecorder import audiorecorder\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the Whisper model\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)\n",
        "\n",
        "st.title(\"Audio Recorder\")\n",
        "audio = audiorecorder(\"Click to record\", \"Click to stop recording\")\n",
        "\n",
        "if len(audio) > 0:\n",
        "    # To play audio in frontend:\n",
        "    st.audio(audio.export().read())\n",
        "\n",
        "    # To save audio to a file, use pydub export method:\n",
        "    audio.export(\"audio.mp3\", format=\"mp3\")\n",
        "\n",
        "    # To get audio properties, use pydub AudioSegment properties:\n",
        "    st.write(f\"Frame rate: {audio.frame_rate}, Frame width: {audio.frame_width}, Duration: {audio.duration_seconds} seconds\")\n",
        "\n",
        "    try:\n",
        "        text = whisper(\"audio.mp3\")['text']\n",
        "        st.write(\"Transcription: \", text)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during transcription: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBtkWcHhoSn6"
      },
      "outputs": [],
      "source": [
        "# Check and kill any existing process on port 8501\n",
        "!fuser -k 8501/tcp\n",
        "!streamlit run audioRecordAndTranscribe.py & npx localtunnel --port 8501 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaM0JHYIG7wa",
        "outputId": "4e66eeac-8589-47d9-f13e-abef11c11705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing youtubeAudioTranscribe.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile youtubeAudioTranscribe.py\n",
        "\n",
        "import streamlit as st\n",
        "from pytube import YouTube\n",
        "from pydub import AudioSegment\n",
        "from transformers import pipeline\n",
        "import os\n",
        "\n",
        "# Initialize the Whisper model\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)\n",
        "\n",
        "st.title(\"YouTube Audio Transcriber\")\n",
        "youtube_url = st.text_input(\"Enter YouTube URL\")\n",
        "\n",
        "if youtube_url:\n",
        "    try:\n",
        "        # Download audio from YouTube\n",
        "        yt = YouTube(youtube_url)\n",
        "        stream = yt.streams.filter(only_audio=True).first()\n",
        "        audio_file = stream.download(filename=\"youtube_audio.mp4\")\n",
        "\n",
        "        # Convert to WAV format for better compatibility\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        audio.export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "        # Display audio properties\n",
        "        st.audio(\"audio.wav\")\n",
        "        st.write(f\"Frame rate: {audio.frame_rate}, Frame width: {audio.frame_width}, Duration: {audio.duration_seconds} seconds\")\n",
        "\n",
        "        st.write(\"Transcribing...\")\n",
        "        # Transcribe audio\n",
        "        text = whisper(\"audio.wav\")['text']\n",
        "        st.write(\"Transcription: \", text)\n",
        "\n",
        "        # Cleanup\n",
        "        os.remove(\"audio.wav\")\n",
        "        os.remove(audio_file)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr__O6aJv1yv"
      },
      "outputs": [],
      "source": [
        "# Check and kill any existing process on port 8501\n",
        "!fuser -k 8501/tcp\n",
        "!streamlit run youtubeAudioTranscribe.py & npx localtunnel --port 8501 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEEm0_orv83a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
=======
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Designed to run on Colab with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o80fU1RwFXC5"
      },
      "outputs": [],
      "source": [
        "! pip install streamlit transformers torch streamlit-audiorecorder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T7HQV9ooK-6",
        "outputId": "eefd9731-e3db-4a7a-dea9-8af28f5b8d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting audioRecordAndPlay.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile audioRecordAndTranscribe.py\n",
        "\n",
        "import streamlit as st\n",
        "from audiorecorder import audiorecorder\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the Whisper model\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)\n",
        "\n",
        "st.title(\"Audio Recorder\")\n",
        "audio = audiorecorder(\"Click to record\", \"Click to stop recording\")\n",
        "\n",
        "if len(audio) > 0:\n",
        "    # To play audio in frontend:\n",
        "    st.audio(audio.export().read())\n",
        "\n",
        "    # To save audio to a file, use pydub export method:\n",
        "    audio.export(\"audio.mp3\", format=\"mp3\")\n",
        "\n",
        "    # To get audio properties, use pydub AudioSegment properties:\n",
        "    st.write(f\"Frame rate: {audio.frame_rate}, Frame width: {audio.frame_width}, Duration: {audio.duration_seconds} seconds\")\n",
        "\n",
        "    try:\n",
        "        text = whisper(\"audio.mp3\")['text']\n",
        "        st.write(\"Transcription: \", text)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during transcription: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBtkWcHhoSn6"
      },
      "outputs": [],
      "source": [
        "# Check and kill any existing process on port 8501\n",
        "!fuser -k 8501/tcp\n",
        "!streamlit run audioRecordAndTranscribe.py & npx localtunnel --port 8501 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaM0JHYIG7wa",
        "outputId": "4e66eeac-8589-47d9-f13e-abef11c11705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing youtubeAudioTranscribe.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile youtubeAudioTranscribe.py\n",
        "\n",
        "import streamlit as st\n",
        "from pytube import YouTube\n",
        "from pydub import AudioSegment\n",
        "from transformers import pipeline\n",
        "import os\n",
        "\n",
        "# Initialize the Whisper model\n",
        "whisper = pipeline('automatic-speech-recognition', model='openai/whisper-medium', device=0)\n",
        "\n",
        "st.title(\"YouTube Audio Transcriber\")\n",
        "youtube_url = st.text_input(\"Enter YouTube URL\")\n",
        "\n",
        "if youtube_url:\n",
        "    try:\n",
        "        # Download audio from YouTube\n",
        "        yt = YouTube(youtube_url)\n",
        "        stream = yt.streams.filter(only_audio=True).first()\n",
        "        audio_file = stream.download(filename=\"youtube_audio.mp4\")\n",
        "\n",
        "        # Convert to WAV format for better compatibility\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        audio.export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "        # Display audio properties\n",
        "        st.audio(\"audio.wav\")\n",
        "        st.write(f\"Frame rate: {audio.frame_rate}, Frame width: {audio.frame_width}, Duration: {audio.duration_seconds} seconds\")\n",
        "\n",
        "        st.write(\"Transcribing...\")\n",
        "        # Transcribe audio\n",
        "        text = whisper(\"audio.wav\")['text']\n",
        "        st.write(\"Transcription: \", text)\n",
        "\n",
        "        # Cleanup\n",
        "        os.remove(\"audio.wav\")\n",
        "        os.remove(audio_file)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr__O6aJv1yv"
      },
      "outputs": [],
      "source": [
        "# Check and kill any existing process on port 8501\n",
        "!fuser -k 8501/tcp\n",
        "!streamlit run youtubeAudioTranscribe.py & npx localtunnel --port 8501 &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEEm0_orv83a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
>>>>>>> vettura/main
