{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ODB-rGPpH_F8",
      "metadata": {
        "id": "ODB-rGPpH_F8"
      },
      "outputs": [],
      "source": [
        "!pip install -q huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8BmdKaKcDf9x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8BmdKaKcDf9x",
        "outputId": "c487b7ed-aee2-4fab-f00b-d537bca78657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 4263, done.\u001b[K\n",
            "remote: Counting objects: 100% (2122/2122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (300/300), done.\u001b[K\n",
            "remote: Total 4263 (delta 1996), reused 1834 (delta 1821), pack-reused 2141 (from 2)\u001b[K\n",
            "Receiving objects: 100% (4263/4263), 29.82 MiB | 43.37 MiB/s, done.\n",
            "Resolving deltas: 100% (3229/3229), done.\n",
            "/content/ai-toolkit\n",
            "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
            "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
            "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
            "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n",
            "Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n",
            "Cloning into '/content/ai-toolkit/repositories/leco'...\n",
            "Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n",
            "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
            "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
            "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
            "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
            "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
            "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
            "The virtual environment was not created successfully because ensurepip is not\n",
            "available.  On Debian/Ubuntu systems, you need to install the python3-venv\n",
            "package using the following command.\n",
            "\n",
            "    apt install python3.10-venv\n",
            "\n",
            "You may need to use sudo with that command.  After installing the python3-venv\n",
            "package, recreate your virtual environment.\n",
            "\n",
            "Failing command: /content/ai-toolkit/venv/bin/python3\n",
            "\n",
            "/bin/bash: line 1: venv/bin/activate: No such file or directory\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.20.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.5.0)\n",
            "Collecting diffusers==0.32.2 (from -r requirements.txt (line 4))\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.47.1)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 7))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 9))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.1)\n",
            "Collecting kornia (from -r requirements.txt (line 11))\n",
            "  Downloading kornia-0.8.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.2.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Collecting albumentations==1.4.15 (from -r requirements.txt (line 16))\n",
            "  Downloading albumentations-1.4.15-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.16 (from -r requirements.txt (line 17))\n",
            "  Downloading albucore-0.0.16-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.10.4)\n",
            "Collecting omegaconf (from -r requirements.txt (line 19))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
            "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.12)\n",
            "Collecting prodigyopt (from -r requirements.txt (line 23))\n",
            "  Downloading prodigyopt-1.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 25))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
            "  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lpips (from -r requirements.txt (line 28))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto==0.2.4 (from -r requirements.txt (line 30))\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.27.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (0.12.0)\n",
            "Collecting gradio (from -r requirements.txt (line 34))\n",
            "  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.20.1->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.20.1->-r requirements.txt (line 2)) (11.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 4)) (8.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.32.2->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.25.0)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
            "Collecting ninja (from optimum-quanto==0.2.4->-r requirements.txt (line 30))\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (69.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.1.3)\n",
            "Collecting kornia_rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
            "  Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.27.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->-r requirements.txt (line 20)) (0.19.1)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.28.1)\n",
            "Collecting huggingface_hub (from -r requirements.txt (line 32))\n",
            "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.10.13)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.2.2)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.15.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.0->gradio->-r requirements.txt (line 34)) (14.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.9.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.32.2->-r requirements.txt (line 4)) (3.21.0)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.32.2->-r requirements.txt (line 4)) (2.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (1.3.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.22.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
            "Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-1.4.15-py3-none-any.whl (200 kB)\n",
            "Downloading albucore-0.0.16-py3-none-any.whl (9.5 kB)\n",
            "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "Downloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.8.0-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.30.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m175.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading gradio-5.15.0-py3-none-any.whl (57.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 MB\u001b[0m \u001b[31m145.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "Downloading kornia_rs-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m139.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m163.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Building wheels for collected packages: lycoris-lora, controlnet_aux, antlr4-python3-runtime\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77136 sha256=6faae7875608059e80d431c769e13cab63cf505d02e1ba3658924fa76147a80b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274342 sha256=4dfd2a2bf4a1fe3743e1b1c7dfbb20b04b84080f54052b14e030100bdc6aabfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=3d06dbe383d8d9d9a82ff343924ea928fe20d32513387b243eb252edcf4b980a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built lycoris-lora controlnet_aux antlr4-python3-runtime\n",
            "Installing collected packages: trampoline, pydub, antlr4-python3-runtime, uvicorn, tomlkit, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, omegaconf, ninja, markupsafe, kornia_rs, hf_transfer, ftfy, flatten_json, ffmpy, aiofiles, starlette, huggingface_hub, albucore, safehttpx, gradio-client, fastapi, diffusers, albumentations, torchsde, torchdiffeq, optimum-quanto, kornia, jsonmerge, invisible-watermark, gradio, dctorch, bitsandbytes, pytorch_fid, lycoris-lora, lpips, clip-anytorch, clean-fid, open_clip_torch, k-diffusion, controlnet_aux\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.31.0.dev0\n",
            "    Uninstalling diffusers-0.31.0.dev0:\n",
            "      Successfully uninstalled diffusers-0.31.0.dev0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed PyWavelets-1.8.0 aiofiles-23.2.1 albucore-0.0.16 albumentations-1.4.15 antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.2 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.32.2 fastapi-0.115.8 ffmpy-0.5.0 flatten_json-0.1.14 ftfy-6.3.1 gradio-5.15.0 gradio-client-1.7.0 hf_transfer-0.1.9 huggingface_hub-0.28.1 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.8.0 kornia_rs-0.1.8 lpips-0.1.4 lycoris-lora-1.8.3 markupsafe-2.1.5 ninja-1.11.1.3 omegaconf-2.3.0 open_clip_torch-2.30.0 optimum-quanto-0.2.4 oyaml-1.0 prodigyopt-1.1.2 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.20 pytorch_fid-0.3.0 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 torchdiffeq-0.2.5 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.34.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e350a27b13bf422abd3fbb6d2a21517a",
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.32.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
            "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate, transformers\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed accelerate-1.3.0 transformers-4.48.3\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ostris/ai-toolkit.git\n",
        "%cd ai-toolkit\n",
        "!git submodule update --init --recursive\n",
        "!python -m venv venv\n",
        "!source venv/bin/activate\n",
        "!pip install torch\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade accelerate transformers diffusers huggingface_hub #Optional, run it if you run into issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24zNrNXyHog4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24zNrNXyHog4",
        "outputId": "b1206ee6-4d82-49af-d5b5-bd291a5bb3c0"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "token = input(\"Enter Huggingface token: \")\n",
        "login(token=token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02G8xG3FC9ri",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02G8xG3FC9ri",
        "outputId": "e7c40b85-3cf3-45e2-f722-9f2dd73f931f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 1 job\n",
            "2025-02-10 17:37:34.020778: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-10 17:37:34.037958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-10 17:37:34.058956: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-10 17:37:34.065378: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-10 17:37:34.080309: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-10 17:37:35.430395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "{\n",
            "    \"type\": \"sd_trainer\",\n",
            "    \"training_folder\": \"/content/output/flux_lora_face\",\n",
            "    \"performance_log_every\": 200,\n",
            "    \"device\": \"cuda:0\",\n",
            "    \"trigger_word\": \"d0g\",\n",
            "    \"network\": {\n",
            "        \"type\": \"lora\",\n",
            "        \"linear\": 32,\n",
            "        \"linear_alpha\": 32\n",
            "    },\n",
            "    \"save\": {\n",
            "        \"dtype\": \"float16\",\n",
            "        \"save_every\": 200,\n",
            "        \"max_step_saves_to_keep\": 4,\n",
            "        \"push_to_hub\": false,\n",
            "        \"hf_repo_id\": \"grudgie/flux-train\",\n",
            "        \"hf_private\": true\n",
            "    },\n",
            "    \"datasets\": [\n",
            "        {\n",
            "            \"folder_path\": \"/content/lora_pics\",\n",
            "            \"caption_ext\": \"txt\",\n",
            "            \"caption_dropout_rate\": 0.05,\n",
            "            \"shuffle_tokens\": false,\n",
            "            \"cache_latents_to_disk\": true,\n",
            "            \"resolution\": [\n",
            "                512,\n",
            "                768,\n",
            "                1024\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"train\": {\n",
            "        \"batch_size\": 1,\n",
            "        \"steps\": 2000,\n",
            "        \"gradient_accumulation_steps\": 1,\n",
            "        \"train_unet\": true,\n",
            "        \"train_text_encoder\": false,\n",
            "        \"gradient_checkpointing\": true,\n",
            "        \"noise_scheduler\": \"flowmatch\",\n",
            "        \"optimizer\": \"adamw8bit\",\n",
            "        \"lr\": 0.0004,\n",
            "        \"ema_config\": {\n",
            "            \"use_ema\": true,\n",
            "            \"ema_decay\": 0.99\n",
            "        },\n",
            "        \"dtype\": \"bf16\"\n",
            "    },\n",
            "    \"model\": {\n",
            "        \"name_or_path\": \"black-forest-labs/FLUX.1-dev\",\n",
            "        \"is_flux\": true,\n",
            "        \"quantize\": true\n",
            "    },\n",
            "    \"sample\": {\n",
            "        \"sampler\": \"flowmatch\",\n",
            "        \"sample_every\": 200,\n",
            "        \"width\": 1024,\n",
            "        \"height\": 1024,\n",
            "        \"prompts\": [\n",
            "            \"[trigger] with red fur, playing chess at the park, bomb going off in the background\",\n",
            "            \"[trigger] dog holding a coffee cup, in a beanie, sitting at a cafe\",\n",
            "            \"[trigger] a labrador is a DJ at a night club, fish eye lens, smoke machine, lazer lights, holding a martini\",\n",
            "            \"[trigger] a dog standing on twos showing off his cool new t shirt at the beach, a shark is jumping out of the water in the background\",\n",
            "            \"[trigger] a bear building a log cabin in the snow covered mountains\",\n",
            "            \"[trigger] female dog playing the guitar, on stage, singing a song, laser lights, punk rocker\",\n",
            "            \"[trigger] hipster dog with a beard, building a chair, in a wood shop\",\n",
            "            \"[trigger] photo of a dog, white background, medium shot, modeling clothing, studio lighting, white backdrop\",\n",
            "            \"[trigger] a dog holding a sign that says, 'this is a sign'\",\n",
            "            \"[trigger] a labrador, in a post apocalyptic world, with a shotgun, in a leather jacket, in a desert, with a motorcycle\"\n",
            "        ],\n",
            "        \"neg\": \"\",\n",
            "        \"seed\": 42,\n",
            "        \"walk_seed\": true,\n",
            "        \"guidance_scale\": 4,\n",
            "        \"sample_steps\": 20\n",
            "    }\n",
            "}\n",
            "Using EMA\n",
            "\n",
            "#############################################\n",
            "# Running job: flux_lora_face\n",
            "#############################################\n",
            "\n",
            "\n",
            "Running  1 process\n",
            "Loading Flux model\n",
            "Loading transformer\n",
            "Quantizing transformer\n",
            "Loading vae\n",
            "Loading t5\n",
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
            "Downloading shards: 100% 2/2 [00:00<00:00, 7557.30it/s]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  2.79it/s]\n",
            "Quantizing T5\n",
            "Loading clip\n",
            "making pipe\n",
            "preparing\n",
            "create LoRA network. base dim (rank): 32, alpha: 32\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder: 0 modules.\n",
            "create LoRA for U-Net: 494 modules.\n",
            "enable LoRA for U-Net\n",
            "Dataset: /content/lora_pics\n",
            "  -  Preprocessing image dimensions\n",
            "100% 10/10 [00:00<00:00, 183.39it/s]\n",
            "  -  Found 10 images\n",
            "Bucket sizes for /content/lora_pics:\n",
            "384x384: 3 files\n",
            "320x256: 4 files\n",
            "256x192: 1 files\n",
            "256x256: 1 files\n",
            "384x320: 1 files\n",
            "5 buckets made\n",
            "Caching latents for /content/lora_pics\n",
            " - Saving latents to disk\n",
            "Caching latents to disk: 100% 10/10 [00:00<00:00, 17.29it/s]\n",
            "Dataset: /content/lora_pics\n",
            "  -  Preprocessing image dimensions\n",
            "100% 10/10 [00:00<00:00, 29228.60it/s]\n",
            "  -  Found 10 images\n",
            "Bucket sizes for /content/lora_pics:\n",
            "384x384: 3 files\n",
            "320x256: 4 files\n",
            "256x192: 1 files\n",
            "256x256: 1 files\n",
            "384x320: 1 files\n",
            "5 buckets made\n",
            "Caching latents for /content/lora_pics\n",
            " - Saving latents to disk\n",
            "Caching latents to disk: 100% 10/10 [00:00<00:00, 19257.59it/s]\n",
            "Dataset: /content/lora_pics\n",
            "  -  Preprocessing image dimensions\n",
            "100% 10/10 [00:00<00:00, 29228.60it/s]\n",
            "  -  Found 10 images\n",
            "Bucket sizes for /content/lora_pics:\n",
            "384x384: 3 files\n",
            "320x256: 4 files\n",
            "256x192: 1 files\n",
            "256x256: 1 files\n",
            "384x320: 1 files\n",
            "5 buckets made\n",
            "Caching latents for /content/lora_pics\n",
            " - Saving latents to disk\n",
            "Caching latents to disk: 100% 10/10 [00:00<00:00, 19213.49it/s]\n",
            "Generating baseline samples before training\n",
            "flux_lora_face:  10% 199/2000 [05:41<50:00,  1.67s/it, lr: 4.0e-04 loss: 3.737e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.81s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.75s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.73s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.72s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 200\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6732s avg - train_loop, num = 10\n",
            " - 0.9104s avg - backward, num = 10\n",
            " - 0.6122s avg - predict_unet, num = 10\n",
            " - 0.1332s avg - reset_batch, num = 6\n",
            " - 0.0675s avg - encode_prompt, num = 10\n",
            " - 0.0639s avg - optimizer_step, num = 10\n",
            " - 0.0016s avg - get_batch, num = 10\n",
            " - 0.0014s avg - preprocess_batch, num = 10\n",
            " - 0.0010s avg - prepare_noise, num = 10\n",
            " - 0.0004s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  20% 399/2000 [11:23<45:37,  1.71s/it, lr: 4.0e-04 loss: 3.204e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.79s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.74s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.73s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.73s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.73s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 400\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6995s avg - train_loop, num = 10\n",
            " - 0.9218s avg - backward, num = 10\n",
            " - 0.6270s avg - predict_unet, num = 10\n",
            " - 0.1346s avg - reset_batch, num = 7\n",
            " - 0.0665s avg - encode_prompt, num = 10\n",
            " - 0.0650s avg - optimizer_step, num = 10\n",
            " - 0.0015s avg - get_batch, num = 10\n",
            " - 0.0013s avg - preprocess_batch, num = 10\n",
            " - 0.0010s avg - prepare_noise, num = 10\n",
            " - 0.0004s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0001s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  30% 599/2000 [17:05<39:40,  1.70s/it, lr: 4.0e-04 loss: 5.401e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.81s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.73s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.72s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 600\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.7298s avg - train_loop, num = 10\n",
            " - 0.9289s avg - backward, num = 10\n",
            " - 0.6234s avg - predict_unet, num = 10\n",
            " - 0.1365s avg - reset_batch, num = 7\n",
            " - 0.0684s avg - encode_prompt, num = 10\n",
            " - 0.0649s avg - optimizer_step, num = 10\n",
            " - 0.0025s avg - get_batch, num = 10\n",
            " - 0.0016s avg - preprocess_batch, num = 10\n",
            " - 0.0011s avg - prepare_noise, num = 10\n",
            " - 0.0004s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  40% 799/2000 [22:46<33:39,  1.68s/it, lr: 4.0e-04 loss: 2.496e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.81s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.73s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.72s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.72s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 800\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6816s avg - train_loop, num = 10\n",
            " - 0.9233s avg - backward, num = 10\n",
            " - 0.6079s avg - predict_unet, num = 10\n",
            " - 0.1366s avg - reset_batch, num = 6\n",
            " - 0.0678s avg - encode_prompt, num = 10\n",
            " - 0.0632s avg - optimizer_step, num = 10\n",
            " - 0.0015s avg - get_batch, num = 10\n",
            " - 0.0014s avg - preprocess_batch, num = 10\n",
            " - 0.0010s avg - prepare_noise, num = 10\n",
            " - 0.0006s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  50% 999/2000 [28:27<28:22,  1.70s/it, lr: 4.0e-04 loss: 2.817e-02]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.80s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.75s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.74s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.74s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.74s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.74s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.74s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.73s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 1000\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "Removing old save: /content/output/flux_lora_face/flux_lora_face/flux_lora_face_000000200.safetensors\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6978s avg - train_loop, num = 10\n",
            " - 0.9231s avg - backward, num = 10\n",
            " - 0.6241s avg - predict_unet, num = 10\n",
            " - 0.1355s avg - reset_batch, num = 7\n",
            " - 0.0663s avg - encode_prompt, num = 10\n",
            " - 0.0649s avg - optimizer_step, num = 10\n",
            " - 0.0015s avg - get_batch, num = 10\n",
            " - 0.0013s avg - preprocess_batch, num = 10\n",
            " - 0.0010s avg - prepare_noise, num = 10\n",
            " - 0.0005s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0001s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  60% 1199/2000 [34:08<22:30,  1.69s/it, lr: 4.0e-04 loss: 9.875e-02]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.80s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.74s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.72s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 1200\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "Removing old save: /content/output/flux_lora_face/flux_lora_face/flux_lora_face_000000400.safetensors\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.7225s avg - train_loop, num = 10\n",
            " - 0.9230s avg - backward, num = 10\n",
            " - 0.6204s avg - predict_unet, num = 10\n",
            " - 0.1355s avg - reset_batch, num = 7\n",
            " - 0.0702s avg - encode_prompt, num = 10\n",
            " - 0.0641s avg - optimizer_step, num = 10\n",
            " - 0.0026s avg - get_batch, num = 10\n",
            " - 0.0016s avg - preprocess_batch, num = 10\n",
            " - 0.0011s avg - prepare_noise, num = 10\n",
            " - 0.0005s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  70% 1399/2000 [39:49<16:56,  1.69s/it, lr: 4.0e-04 loss: 2.786e-02]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.82s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.73s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.72s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 1400\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "Removing old save: /content/output/flux_lora_face/flux_lora_face/flux_lora_face_000000600.safetensors\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6887s avg - train_loop, num = 10\n",
            " - 0.9275s avg - backward, num = 10\n",
            " - 0.6103s avg - predict_unet, num = 10\n",
            " - 0.1351s avg - reset_batch, num = 6\n",
            " - 0.0672s avg - encode_prompt, num = 10\n",
            " - 0.0643s avg - optimizer_step, num = 10\n",
            " - 0.0015s avg - get_batch, num = 10\n",
            " - 0.0013s avg - preprocess_batch, num = 10\n",
            " - 0.0009s avg - prepare_noise, num = 10\n",
            " - 0.0004s avg - calculate_loss, num = 10\n",
            " - 0.0001s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  80% 1599/2000 [45:31<11:24,  1.71s/it, lr: 4.0e-04 loss: 1.121e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.80s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.74s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.73s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.72s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.72s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 1600\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "Removing old save: /content/output/flux_lora_face/flux_lora_face/flux_lora_face_000000800.safetensors\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.6976s avg - train_loop, num = 10\n",
            " - 0.9243s avg - backward, num = 10\n",
            " - 0.6257s avg - predict_unet, num = 10\n",
            " - 0.1356s avg - reset_batch, num = 7\n",
            " - 0.0658s avg - encode_prompt, num = 10\n",
            " - 0.0627s avg - optimizer_step, num = 10\n",
            " - 0.0015s avg - get_batch, num = 10\n",
            " - 0.0013s avg - preprocess_batch, num = 10\n",
            " - 0.0009s avg - prepare_noise, num = 10\n",
            " - 0.0005s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0001s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face:  90% 1799/2000 [51:12<05:39,  1.69s/it, lr: 4.0e-04 loss: 1.056e-01]\n",
            "Generating Images:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Generating Images:  10% 1/10 [00:18<02:49, 18.82s/it]\u001b[A\n",
            "Generating Images:  20% 2/10 [00:37<02:30, 18.76s/it]\u001b[A\n",
            "Generating Images:  30% 3/10 [00:56<02:11, 18.74s/it]\u001b[A\n",
            "Generating Images:  40% 4/10 [01:14<01:52, 18.74s/it]\u001b[A\n",
            "Generating Images:  50% 5/10 [01:33<01:33, 18.73s/it]\u001b[A\n",
            "Generating Images:  60% 6/10 [01:52<01:14, 18.73s/it]\u001b[A\n",
            "Generating Images:  70% 7/10 [02:11<00:56, 18.73s/it]\u001b[A\n",
            "Generating Images:  80% 8/10 [02:29<00:37, 18.73s/it]\u001b[A\n",
            "Generating Images:  90% 9/10 [02:48<00:18, 18.73s/it]\u001b[A\n",
            "Generating Images: 100% 10/10 [03:07<00:00, 18.72s/it]\u001b[A\n",
            "                                                      \u001b[ASaving at step 1800\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n",
            "Removing old save: /content/output/flux_lora_face/flux_lora_face/flux_lora_face_000001000.safetensors\n",
            "\n",
            "Timer 'flux_lora_face Timer':\n",
            " - 1.7224s avg - train_loop, num = 10\n",
            " - 0.9287s avg - backward, num = 10\n",
            " - 0.6163s avg - predict_unet, num = 10\n",
            " - 0.1359s avg - reset_batch, num = 7\n",
            " - 0.0689s avg - encode_prompt, num = 10\n",
            " - 0.0640s avg - optimizer_step, num = 10\n",
            " - 0.0027s avg - get_batch, num = 10\n",
            " - 0.0015s avg - preprocess_batch, num = 10\n",
            " - 0.0011s avg - prepare_noise, num = 10\n",
            " - 0.0004s avg - calculate_loss, num = 10\n",
            " - 0.0002s avg - prepare_latents, num = 10\n",
            " - 0.0001s avg - scheduler_step, num = 10\n",
            " - 0.0001s avg - batch_cleanup, num = 10\n",
            " - 0.0000s avg - grad_setup, num = 10\n",
            " - 0.0000s avg - prepare_prompt, num = 10\n",
            " - 0.0000s avg - log_to_tensorboard, num = 2\n",
            "\n",
            "flux_lora_face: 100% 1999/2000 [56:52<00:01,  1.71s/it, lr: 4.0e-04 loss: 3.945e-02]\n",
            "\n",
            "Saved to /content/output/flux_lora_face/flux_lora_face/optimizer.pt\n"
          ]
        }
      ],
      "source": [
        "!python ai-toolkit/run.py \"/content/lora_face_flux.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mGhS6z68o6qG",
      "metadata": {
        "id": "mGhS6z68o6qG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4XRzeaXA1jx7",
      "metadata": {
        "id": "4XRzeaXA1jx7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Image Fine Tuning using Lora Flux.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
